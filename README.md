# Xenith

**Ultra-fast, on-device voice assistant for Linux**

Xenith is a fully local voice assistant that runs entirely on your hardware with no cloud dependencies. Optimized for Intel Core Ultra processors, it achieves **~1.5-2.5 second response times** from wake word to audio output.

![Response Time](https://img.shields.io/badge/Response%20Time-1.5--2.5s-brightgreen)
![Power](https://img.shields.io/badge/Power-15--30W%20Active-blue)
![Privacy](https://img.shields.io/badge/Privacy-100%25%20Local-green)

## Features

- ğŸ¤ **Wake Word Detection** - Always listening with ultra-low power (~2-3W)
- ğŸ§  **Local LLM** - Qwen2.5-1.5B runs entirely on-device
- ğŸ”Š **Natural TTS** - High-quality Piper neural voices
- âš¡ **Streaming Response** - Audio starts playing as LLM generates
- ğŸ”’ **100% Private** - No data leaves your device
- ğŸ¨ **Beautiful UI** - Animated plasma widget shows voice state

## Quick Start

```bash
# Install dependencies
make install

# Run Xenith
make run
```

Say **"Hi"** to activate, then speak your command!

## Performance

| Stage | Time |
|-------|------|
| Wake word â†’ Detection | ~500ms |
| STT Processing | ~300ms |
| LLM First Token | ~200ms |
| TTS â†’ Audio | ~100ms |
| **Total to First Audio** | **~1.5s** |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     XENITH VOICE PIPELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   ğŸ¤ Microphone                                                     â”‚
â”‚        â”‚ (continuous audio stream)                                  â”‚
â”‚        â–¼                                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   Wake Word      â”‚  "Hi" detection                              â”‚
â”‚   â”‚   Detection      â”‚  â€¢ Whisper on NPU (~2-3W)                    â”‚
â”‚   â”‚                  â”‚  â€¢ 0.5s check interval                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   Speech-to-Text â”‚  Whisper STT                                 â”‚
â”‚   â”‚   (STT)          â”‚  â€¢ OpenVINO on NPU                           â”‚
â”‚   â”‚                  â”‚  â€¢ 0.3s silence threshold                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚            â”‚ text                                                   â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   LLM Brain      â”‚  Qwen2.5-1.5B                                â”‚
â”‚   â”‚                  â”‚  â€¢ OpenVINO on CPU (fast, ~200ms warmup)     â”‚
â”‚   â”‚                  â”‚  â€¢ Token streaming enabled                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚            â”‚ streaming tokens                                       â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   Sentence       â”‚  Buffers tokens until sentence complete      â”‚
â”‚   â”‚   Buffer         â”‚  â€¢ Min 3 chars, ends on .!?;,:               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚            â”‚ sentences                                              â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   TTS (Piper)    â”‚  Neural text-to-speech                       â”‚
â”‚   â”‚                  â”‚  â€¢ ~100ms per sentence                       â”‚
â”‚   â”‚                  â”‚  â€¢ In-memory audio (no file I/O)             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚            â”‚ numpy audio                                            â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚   â”‚   Audio Player   â”‚  Real-time playback                          â”‚
â”‚   â”‚                  â”‚  â€¢ Direct sounddevice output                 â”‚
â”‚   â”‚                  â”‚  â€¢ 10ms queue polling                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚   ğŸ”Š Speakers                                                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow (Optimized)

All audio data flows **in-memory** with zero file I/O in the critical path:

```
Mic â†’ numpy â†’ STT(NPU) â†’ text â†’ LLM(CPU) â†’ tokens â†’ TTS(CPU) â†’ numpy â†’ speakers
      â†‘                                                              â†‘
      â””â”€â”€ in-memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Hardware Requirements

### Minimum
- Intel Core Ultra (Meteor Lake) or newer
- 8GB RAM
- 5GB disk space

### Recommended
- Intel Core Ultra 7/9
- 16GB RAM
- Intel Arc GPU (optional, for larger models)

## Configuration

Edit `config/config.yaml`:

```yaml
llm:
  # CPU recommended for fast response (~200ms warmup)
  # NPU is low power but slow (~2.3s warmup per query)
  device: "CPU"
  model: "qwen2.5-1.5b"

audio:
  stt:
    device: "auto"  # NPU â†’ Intel GPU â†’ CPU
    model: "base"
  tts:
    voice: "EN-Default"  # Ryan male voice (high quality)
```

## Device Trade-offs

| Device | LLM Warmup | Power | Best For |
|--------|------------|-------|----------|
| CPU | ~200ms | ~15-30W | **Fast response (recommended)** |
| NPU | ~2,300ms | ~3-5W | Battery life |
| GPU | ~300ms | ~30-50W | Larger models |

## Project Structure

```
src/
â”œâ”€â”€ app.py                  # Main GTK application
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ widgets/
â”‚   â””â”€â”€ plasma_widget.py    # Animated voice indicator
â””â”€â”€ audio/
    â”œâ”€â”€ voice_input.py      # Wake word & STT handling
    â”œâ”€â”€ streaming_pipeline.py  # LLM + TTS streaming
    â”œâ”€â”€ pipeline_metrics.py    # Performance tracking
    â”œâ”€â”€ stt_backends/       # Speech-to-Text
    â”‚   â”œâ”€â”€ openvino_backend.py
    â”‚   â””â”€â”€ whisper_backend.py
    â”œâ”€â”€ llm_backends/       # Language Models
    â”‚   â””â”€â”€ openvino_backend.py
    â””â”€â”€ tts_backends/       # Text-to-Speech
        â”œâ”€â”€ piper_backend.py
        â””â”€â”€ melotts_backend.py
```

## Testing

```bash
# Test STT backends
python test_stt_backends.py

# Test TTS backends
python test_tts_backends.py

# Test LLM backends
python test_llm_backends.py

# Test full pipeline
python test_streaming_pipeline.py
```

## Documentation

- [Voice Pipeline Architecture](docs/VOICE_PIPELINE.md)
- [Intel NPU Setup Guide](docs/INTEL_NPU_SETUP.md)
- [STT Backends Reference](docs/STT_BACKENDS.md)
- [TTS Backends Reference](docs/TTS_BACKENDS.md)
- [LLM Backends Reference](docs/LLM_BACKENDS.md)
- [Scripts Reference](docs/SCRIPTS.md)

## Performance Tuning

### For Fastest Response (~1.5s)
```yaml
llm:
  device: "CPU"  # 12x faster than NPU
audio:
  tts:
    voice: "EN-Fast"  # Medium quality, faster synthesis
```

### For Lowest Power (~3-5W active)
```yaml
llm:
  device: "NPU"  # Slower but efficient
audio:
  stt:
    device: "NPU"
```

## License

MIT License - See LICENSE file for details.

